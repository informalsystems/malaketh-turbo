use bytes::Bytes;
use color_eyre::eyre::{self, eyre};
use ssz::{Decode, Encode};
use tracing::{debug, error, info};

use crate::state::{decode_value, State};

use alloy_rpc_types_engine::ExecutionPayloadV3;
use malachitebft_app_channel::app::streaming::StreamContent;
use malachitebft_app_channel::app::types::codec::Codec;
use malachitebft_app_channel::app::types::core::{Round, Validity};
use malachitebft_app_channel::app::types::sync::RawDecidedValue;
use malachitebft_app_channel::app::types::{LocallyProposedValue, ProposedValue};
use malachitebft_app_channel::{AppMsg, Channels, ConsensusMsg, NetworkMsg};
use malachitebft_reth_engine::engine::Engine;
use malachitebft_reth_types::codec::proto::ProtobufCodec;
use malachitebft_reth_types::TestContext;

pub async fn run(
    state: &mut State,
    channels: &mut Channels<TestContext>,
    engine: Engine,
) -> eyre::Result<()> {
    while let Some(msg) = channels.consensus.recv().await {
        match msg {
            // The first message to handle is the `ConsensusReady` message, signaling to the app
            // that Malachite is ready to start consensus
            AppMsg::ConsensusReady { reply } => {
                info!("ðŸŸ¢ Consensus is ready");

                // Node start-up: https://hackmd.io/@danielrachi/engine_api#Node-startup
                // Check compatibility with execution client
                engine.check_capabilities().await?;

                // Get the latest block from the execution engine
                let latest_block = engine.api.get_block_by_number("latest").await?.unwrap();
                debug!("ðŸ‘‰ latest_block: {:?}", latest_block);
                state.head_block_hash = Some(latest_block.block_hash);

                // We can simply respond by telling the engine to start consensus
                // at the current height, which is initially 1
                if reply
                    .send(ConsensusMsg::StartHeight(
                        state.current_height,
                        state.get_validator_set().clone(),
                    ))
                    .is_err()
                {
                    error!("Failed to send ConsensusReady reply");
                }
            }

            // The next message to handle is the `StartRound` message, signaling to the app
            // that consensus has entered a new round (including the initial round 0)
            AppMsg::StartedRound {
                height,
                round,
                proposer,
            } => {
                info!(%height, %round, %proposer, "ðŸŸ¢ Started round");

                // We can use that opportunity to update our internal state
                state.current_height = height;
                state.current_round = round;
                state.current_proposer = Some(proposer);
            }

            // At some point, we may end up being the proposer for that round, and the consensus engine
            // will then ask us for a value to propose to the other validators.
            AppMsg::GetValue {
                height,
                round,
                timeout: _,
                reply,
            } => {
                // NOTE: We can ignore the timeout as we are building the value right away.
                // If we were let's say reaping as many txes from a mempool and executing them,
                // then we would need to respect the timeout and stop at a certain point.

                info!(%height, %round, "ðŸŸ¢ Consensus is requesting a value to propose");

                // We need to ask the execution engine for a new value to
                // propose. Then we send it back to consensus.
                let head_block_hash = state.head_block_hash.expect("Head block hash is not set");
                let execution_payload = engine.generate_block(head_block_hash).await?;
                debug!(
                    "ðŸŒˆ Got execution payload (block) from execution engine: {:?}",
                    execution_payload
                );

                // Store block in state and propagate to peers.
                let bytes = Bytes::from(execution_payload.as_ssz_bytes());

                // Prepare block proposal.
                let proposal: LocallyProposedValue<TestContext> =
                    state.propose_value(height, round, bytes.clone()).await?;

                // When the node is not the proposer, store the block data,
                // which will be passed to the execution client (EL) on commit.
                state.store_undecided_proposal_data(bytes.clone()).await?;

                // Send it to consensus
                if reply.send(proposal.clone()).is_err() {
                    error!("Failed to send GetValue reply");
                }

                // Now what's left to do is to break down the value to propose into parts,
                // and send those parts over the network to our peers, for them to re-assemble the full value.
                for stream_message in state.stream_proposal(proposal, bytes) {
                    info!(%height, %round, "Streaming proposal part: {stream_message:?}");
                    channels
                        .network
                        .send(NetworkMsg::PublishProposalPart(stream_message))
                        .await?;
                }
                debug!(%height, %round, "âœ… Proposal sent");
            }

            // On the receiving end of these proposal parts (ie. when we are not the proposer),
            // we need to process these parts and re-assemble the full value.
            // To this end, we store each part that we receive and assemble the full value once we
            // have all its constituent parts. Then we send that value back to consensus for it to
            // consider and vote for or against it (ie. vote `nil`), depending on its validity.
            AppMsg::ReceivedProposalPart { from, part, reply } => {
                let (part_type, part_size) = match &part.content {
                    StreamContent::Data(part) => (part.get_type(), part.size_bytes()),
                    StreamContent::Fin => ("end of stream", 0),
                };

                info!(
                    %from, %part.sequence, part.type = %part_type, part.size = %part_size,
                    "Received proposal part"
                );

                let proposed_value = state.received_proposal_part(from, part).await?;
                if let Some(proposed_value) = proposed_value.clone() {
                    debug!("âœ… Received complete proposal: {:?}", proposed_value);
                }

                if reply.send(proposed_value).is_err() {
                    error!("Failed to send ReceivedProposalPart reply");
                }
            }

            // In some cases, e.g. to verify the signature of a vote received at a higher height
            // than the one we are at (e.g. because we are lagging behind a little bit),
            // the engine may ask us for the validator set at that height.
            //
            // In our case, our validator set stays constant between heights so we can
            // send back the validator set found in our genesis state.
            AppMsg::GetValidatorSet { height: _, reply } => {
                if reply.send(state.get_validator_set().clone()).is_err() {
                    error!("ðŸ”´ Failed to send GetValidatorSet reply");
                }
            }

            // After some time, consensus will finally reach a decision on the value
            // to commit for the current height, and will notify the application,
            // providing it with a commit certificate which contains the ID of the value
            // that was decided on as well as the set of commits for that value,
            // ie. the precommits together with their (aggregated) signatures.
            AppMsg::Decided {
                certificate, reply, ..
            } => {
                info!(
                    height = %certificate.height, round = %certificate.round,
                    value = %certificate.value_id,
                    "ðŸŸ¢ Consensus has decided on value"
                );

                let block_bytes = state
                    .get_block_data(certificate.height, certificate.round)
                    .await
                    .expect("certificate should have associated block data");

                let execution_payload = ExecutionPayloadV3::from_ssz_bytes(&block_bytes).unwrap();
                let parent_block_hash = execution_payload.payload_inner.payload_inner.parent_hash;
                let new_block_hash = execution_payload.payload_inner.payload_inner.block_hash;
                assert_eq!(state.head_block_hash, Some(parent_block_hash));

                // If the node is not the proposer, provide the received block
                // to the execution client (EL).
                if !state.is_current_proposer() {
                    let payload_status = engine.notify_new_block(execution_payload).await?;
                    if payload_status.status.is_invalid() {
                        return Err(eyre!("Invalid payload status: {}", payload_status.status));
                    }
                    debug!(
                        "ðŸ’¡ New block added at height {} with hash: {}",
                        certificate.height, new_block_hash
                    );
                }

                // Notify the execution client (EL) of the new block.
                // Update the execution head state to this block.
                let latest_valid_hash = engine.set_latest_forkchoice_state(new_block_hash).await?;
                debug!(
                    "ðŸš€ Forkchoice updated to height {} with block hash: {}, latest_valid_hash: {}",
                    certificate.height, new_block_hash, latest_valid_hash
                );

                // When that happens, we store the decided value in our store
                state.commit(certificate).await?;

                // Update the head block hash
                state.head_block_hash = Some(new_block_hash);

                // Pause briefly before starting next height, just to make following the logs easier
                // tokio::time::sleep(Duration::from_secs(1)).await;

                // And then we instruct consensus to start the next height
                if reply
                    .send(ConsensusMsg::StartHeight(
                        state.current_height,
                        state.get_validator_set().clone(),
                    ))
                    .is_err()
                {
                    error!("Failed to send Decided reply");
                }
            }

            // It may happen that our node is lagging behind its peers. In that case,
            // a synchronization mechanism will automatically kick to try and catch up to
            // our peers. When that happens, some of these peers will send us decided values
            // for the heights in between the one we are currently at (included) and the one
            // that they are at. When the engine receives such a value, it will forward to the application
            // to decode it from its wire format and send back the decoded value to consensus.
            //
            // TODO: store the received value somewhere here
            AppMsg::ProcessSyncedValue {
                height,
                round,
                proposer,
                value_bytes,
                reply,
            } => {
                info!(%height, %round, "ðŸŸ¢ Processing synced value");

                let value = decode_value(value_bytes);

                // We send to consensus to see if it has been decided on
                if reply
                    .send(ProposedValue {
                        height,
                        round,
                        valid_round: Round::Nil,
                        proposer,
                        value,
                        validity: Validity::Valid,
                    })
                    .is_err()
                {
                    error!("Failed to send ProcessSyncedValue reply");
                }
            }

            // If, on the other hand, we are not lagging behind but are instead asked by one of
            // our peer to help them catch up because they are the one lagging behind,
            // then the engine might ask the application to provide with the value
            // that was decided at some lower height. In that case, we fetch it from our store
            // and send it to consensus.
            AppMsg::GetDecidedValue { height, reply } => {
                info!(%height, "ðŸŸ¢ GetDecidedValue");
                let decided_value = state.get_decided_value(height).await;

                let raw_decided_value = decided_value.map(|decided_value| RawDecidedValue {
                    certificate: decided_value.certificate,
                    value_bytes: ProtobufCodec.encode(&decided_value.value).unwrap(),
                });

                if reply.send(raw_decided_value).is_err() {
                    error!("Failed to send GetDecidedValue reply");
                }
            }

            // In order to figure out if we can help a peer that is lagging behind,
            // the engine may ask us for the height of the earliest available value in our store.
            AppMsg::GetHistoryMinHeight { reply } => {
                let min_height = state.get_earliest_height().await;

                if reply.send(min_height).is_err() {
                    error!("Failed to send GetHistoryMinHeight reply");
                }
            }

            AppMsg::RestreamProposal { .. } => {
                error!("ðŸ”´ RestreamProposal not implemented");
            }

            AppMsg::ExtendVote { reply, .. } => {
                if reply.send(None).is_err() {
                    error!("ðŸ”´ Failed to send ExtendVote reply");
                }
            }

            AppMsg::VerifyVoteExtension { reply, .. } => {
                if reply.send(Ok(())).is_err() {
                    error!("ðŸ”´ Failed to send VerifyVoteExtension reply");
                }
            }

            AppMsg::PeerJoined { peer_id } => {
                info!(%peer_id, "ðŸŸ¢ Peer joined our local view of network");

                // You might want to track connected peers in your state
                state.peers.insert(peer_id);
            }

            AppMsg::PeerLeft { peer_id } => {
                info!(%peer_id, "ðŸ”´ Peer left our local view of network");

                // Remove the peer from tracking
                state.peers.remove(&peer_id);
            }
        }
    }

    // If we get there, it can only be because the channel we use to receive message
    // from consensus has been closed, meaning that the consensus actor has died.
    // We can do nothing but return an error here.
    Err(eyre!("Consensus channel closed unexpectedly"))
}
